name: Property Search

on:
  # schedule:
  #   - cron: '15 * * * *'
  workflow_dispatch:
    inputs:
      mode:
        description: 'Run mode'
        required: true
        default: 'prod'
        type: choice
        options: [prod, dev]
      skip_crawl:
        description: 'Skip crawling'
        required: false
        type: boolean
        default: false
      force_recrawl:
        description: 'Force recrawl stale properties'
        required: false
        type: boolean
        default: false
      url:
        description: 'Optional single location URL'
        required: false
        type: string
        default: ''
      batch_size:
        description: 'Number of URLs to crawl from queue'
        required: false
        type: string
        default: '1'

jobs:
  scrape_and_visualize:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetches full history so rebase/push works reliably

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          playwright install chromium --with-deps

      - name: Run Tests
        env:
          PYTHONPATH: .
        run: |
          pytest tests/*.py

      - name: Run Scraper
        if: github.event.inputs.skip_crawl != 'true'
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          P4N_USERNAME: ${{ secrets.P4N_USERNAME }}
          P4N_PASSWORD: ${{ secrets.P4N_PASSWORD }}
        run: |
          # Always start with the --force flag to stop staleness checks
          ARGS=("--force")
          
          if [[ "${{ github.event.inputs.mode }}" == "dev" ]]; then ARGS+=("--dev"); fi
          
          # Allow the manual trigger to still control force if needed, 
          # but the base ARGS ensures it is always on.
          if [[ "${{ github.event.inputs.force_recrawl }}" == "true" ]]; then ARGS+=("--force"); fi
          
          if [[ -n "${{ github.event.inputs.url }}" ]]; then ARGS+=("--url" "${{ github.event.inputs.url }}"); fi
          
          if [[ -n "${{ github.event.inputs.batch_size }}" ]]; then ARGS+=("--batch_size" "${{ github.event.inputs.batch_size }}"); fi
          
          python backbone_crawler.py "${ARGS[@]}"

      - name: Set Intelligence Environment
        run: |
          if [ -f "backbone_locations_dev.csv" ]; then
            echo "INPUT_CSV=backbone_locations_dev.csv" >> $GITHUB_ENV
            echo "CSV_FILE=backbone_locations_dev.csv" >> $GITHUB_ENV
          else
            echo "INPUT_CSV=backbone_locations.csv" >> $GITHUB_ENV
            echo "CSV_FILE=backbone_locations.csv" >> $GITHUB_ENV
          fi

      - name: Run Demand Analyzer
        run: python demand_analyzer.py

      - name: Generate Visualization
        run: python visualize_land.py

      - name: Upload Pipeline Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-debug-package
          path: |
            pipeline_execution.log
            strategic_analysis.json
            *.csv
            index.html
            *.mp4

      - name: Commit and Push (Prod Only)
        if: github.event_name == 'schedule' || github.event.inputs.mode == 'prod'
        run: |
          git config --global user.name "P4N Bot"
          git config --global user.email "bot@github.com"
          
          # 1. Fetch latest changes without merging yet
          git fetch origin main
          
          # 2. Stage the specific files we care about
          for file in backbone_locations.csv index.html queue_state.json strategic_analysis.json; do
            if [ -f "$file" ]; then git add "$file"; fi
          done
          
          # 3. Check if there is actually anything to commit
          if ! git diff --staged --quiet; then
            git commit -m "Auto-update strategic intelligence [skip ci]"
            
            # 4. Use 'Strategy-Ours' to prioritize bot data or simply pull before push
            # This handles the conflict by merging remote changes but keeping our new files
            git pull origin main --rebase --strategy-option=theirs
            
            git push origin main
          else
            echo "No changes detected. Skipping push."
          fi
