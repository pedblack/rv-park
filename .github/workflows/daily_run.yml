name: Daily Land Search & Map

on:
  schedule:
    - cron: '0 8 * * *' # 08:00 UTC daily
  workflow_dispatch: 

jobs:
  scrape_and_visualize:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write  # CRITICAL: Allows the bot to push CSV and HTML updates

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright Browsers
        run: playwright install chromium --with-deps

      - name: Run Atomic Scraper & Gemini AI Analysis
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          P4N_USERNAME: ${{ secrets.P4N_USERNAME }}
          P4N_PASSWORD: ${{ secrets.P4N_PASSWORD }}
        run: python backbone_crawler.py

      - name: Generate Geospatial Visualization
        run: python visualize_land.py

      - name: Commit and Push Updated Data & Map
        run: |
          git config --global user.name "P4N Bot"
          git config --global user.email "bot@github.com"
          
          # Stage the CSV database and the generated HTML map
          git add backbone_locations.csv portugal_land_map.html
          
          # Check for changes before committing to prevent empty commit errors
          if git diff --staged --quiet; then
            echo "No new data discovered today. Skipping commit."
          else
            git commit -m "Auto-update Land Database & Map [skip ci]"
            # Use rebase to handle cases where files changed on the server during the run
            git pull --rebase origin main
            git push origin main
          fi
