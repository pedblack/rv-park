name: Daily Park4Night Scraper

on:
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  scrape_and_store:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python Dependencies
        run: |
          pip install playwright playwright-stealth pandas tenacity httpx

      - name: Install Playwright Browsers & Deps
        run: |
          # Installs Chromium and the system-level libraries required to run it
          playwright install chromium --with-deps

      - name: Run Park4Night Crawler
        run: python backbone_crawler.py

      - name: Commit and Push Data
        run: |
          git config --global user.name "P4N Bot"
          git config --global user.email "bot@github.com"
          
          # 1. Stage the changes
          git add backbone_locations.csv
          
          # 2. Commit only if there are changes
          git commit -m "Auto-update Portugal locations [skip ci]" || echo "No changes to commit"
          
          # 3. Pull latest changes with rebase to avoid merge conflicts
          # This handles the "fetch first" error you encountered
          git pull --rebase origin main
          
          # 4. Push the combined work back to the repo
          git push origin main
